{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57fbc0a-6a81-478d-81d8-2a3959d8e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from experiments.mmshap import compute_mm_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c381f87b-8128-424d-b6ee-957b0586fdeb",
   "metadata": {},
   "source": [
    "# Parse output json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd01d086-5c86-4a42-a602-18446e83b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_output(json_list):\n",
    "    \"\"\"\n",
    "    receive a list of output files. load then and combine them into a single one.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for jf in json_list:\n",
    "        with open(jf, \"r\") as f:\n",
    "            data.append(json.load(f))\n",
    "    return data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b091c710-fe85-4814-8628-a0939e2c65cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mullama_fs_list = glob.glob(\"../data/output_data/mullama_muchomusic_musiccaps_fs/*.json\")\n",
    "qwen_fs_list = glob.glob(\"../data/output_data/qwenaudio_muchomusic_musiccaps_fs/*.json\")\n",
    "qwen_desc_list = glob.glob(\"../data/output_data/qwenaudio_muchomusic_musiccaps_desc/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c1d050-955c-48bd-9be4-668a65b2e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_fs = combine_output(qwen_fs_list)\n",
    "qwen_desc = combine_output(qwen_desc_list)\n",
    "mu_fs = combine_output(mullama_fs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fd6d1b-e38f-423c-8107-12eb72c84ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/output_data/qwen_fs.json\", \"w\") as f:\n",
    "    json.dump(qwen_fs, f)\n",
    "\n",
    "with open(\"../data/output_data/qwen_desc.json\", \"w\") as f:\n",
    "    json.dump(qwen_desc, f)\n",
    "    \n",
    "with open(\"../data/output_data/mullama_fs.json\", \"w\") as f:\n",
    "    json.dump(mu_fs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c725692-4e4e-4dae-9011-7339e55df92c",
   "metadata": {},
   "source": [
    "# Compute MM-SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7a10b-f9d8-435e-a862-5cc029aa6f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer_pandas(\n",
    "    model_output, \n",
    "    answer_options, \n",
    "    prefix=\"The correct answer is:\", \n",
    "    letter_options=[\"A\", \"B\", \"C\", \"D\"]):\n",
    "    \"\"\" adaptation of muchomusic function but applies to our pandas dataframe \"\"\"\n",
    "\n",
    "    output = model_output.split(prefix)[-1].strip()\n",
    "    response = list(set(letter_options).intersection(output))\n",
    "    if len(response) == 1:\n",
    "        final_response = letter_options.index(response[0])\n",
    "    else:\n",
    "        normalized_output = output.lower().strip()\n",
    "        normalized_answers = [j.lower().strip() for j in answer_options]\n",
    "\n",
    "        for j, answer in enumerate(normalized_answers):\n",
    "            if answer in normalized_output:\n",
    "                final_response = j\n",
    "                break\n",
    "            else:\n",
    "                final_response = -1\n",
    "    return final_response\n",
    "\n",
    "def compare_answers(response, answer_orders):\n",
    "    \"\"\"\n",
    "    return correct/incorrect/unanswered\n",
    "    \"\"\"\n",
    "    answer = 0\n",
    "    if response == answer_orders.index(0):\n",
    "        answer = 1\n",
    "    elif response == -1:\n",
    "        answer = -1\n",
    "\n",
    "    return answer\n",
    "\n",
    "def accuracy(df):\n",
    "    return df[df[\"final_answer\"] == 1][\"final_answer\"].count()/df[\"final_answer\"].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7b0b5c-7a77-49f2-8408-23bc07d1dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mmshap_row(row):\n",
    "    base_folder = \"..\"\n",
    "    data_folder = os.path.join(base_folder, row.output_folder)\n",
    "    \n",
    "    shapley_values = np.load(os.path.join(data_folder, f\"{row.question_id}_shapley_values.npy\"))\n",
    "    tokens = np.load(os.path.join(data_folder, f\"{row.question_id}_tokens.npy\")).squeeze(0).squeeze(0)\n",
    "    \n",
    "    audio_length = len(np.where(tokens < 0)[0])\n",
    "    audio_score, text_score = compute_mm_score(shap_values=shapley_values, audio_length=audio_length, method=\"sum\")\n",
    "    \n",
    "    return pd.Series({\"a-shap\": audio_score, \"t-shap\": text_score, \"tokens\": tokens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7b649a-1ed4-4c71-a909-c50ae2aedeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qfs = pd.read_json(\"../data/output_data/qwen_fs.json\")\n",
    "mfs = pd.read_json(\"../data/output_data/mullama_fs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758dedb-09d7-4a96-a48e-bebfed03b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qfs[\"extracted_response\"] = qfs[[\"model_output\", \"answers\"]].apply(lambda x: extract_answer_pandas(x.model_output, x.answers), axis=1)\n",
    "qfs[\"final_answer\"] = qfs[[\"extracted_response\", \"answer_orders\"]].apply(lambda x: compare_answers(x.extracted_response, x.answer_orders), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8224d8-a5b4-4229-828b-813d746d30c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfs[\"extracted_response\"] = mfs[[\"model_output\", \"answers\"]].apply(lambda x: extract_answer_pandas(x.model_output, x.answers), axis=1)\n",
    "mfs[\"final_answer\"] = mfs[[\"extracted_response\", \"answer_orders\"]].apply(lambda x: compare_answers(x.extracted_response, x.answer_orders), axis=1)\n",
    "mfs[\"question\"] = mfs[[\"prompt\"]].apply(lambda x: x.prompt.split(\"Question: \")[-1], axis=1)\n",
    "mfs[\"audio_path\"] = mfs[[\"audio_path\"]].apply(lambda x: x.audio_path.replace(\"data/\", \"\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c61f886-0a80-41fd-beea-044ebc263482",
   "metadata": {},
   "outputs": [],
   "source": [
    "qfs[[\"a_shap\", \"t_shap\", \"tokens\"]] = qfs.apply(compute_mmshap_row, axis=1)\n",
    "mfs[[\"a_shap\", \"t_shap\", \"tokens\"]] = mfs.apply(compute_mmshap_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dba4a58-f9f6-462a-97c0-d7a433e19683",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfs[mfs[\"final_answer\"] == 1][[\"question\", \"model_output\", \"a_shap\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0f63ac-6624-43ea-bc2a-ba019e6e5c29",
   "metadata": {},
   "source": [
    "# Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11158071-5af2-4afc-9f49-56863f5c0b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b3afaf-e559-4fb8-bffc-24ad7cd09256",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfs[mfs[\"final_answer\"] == 1][[\"question_id\", \"question\", \"a_shap\", \"tokens\", \"audio_path\"]].sort_values(by=\"a_shap\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d2ea7c-3104-454d-93c4-035febc5577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = mfs[mfs[\"question_id\"] == 869]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c31f6f-7ca8-448e-a412-48f8666f4542",
   "metadata": {},
   "outputs": [],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858c6b0-28af-4746-849e-677beea42e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path\n",
    "dataset_path = \"/media/gigibs/DD02EEEC68459F17/datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20d11a5-1fc2-4938-9fa4-71177a928df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load audio\n",
    "x, fs = librosa.load(os.path.join(dataset_path, example[\"audio_path\"].values[0]), sr=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b91255b-9919-46c5-8da9-db91154c9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324493fb-3505-4510-97b0-285dea837047",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28216a1-0e52-4871-a493-3d3adc341c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_path = os.path.join(\"..\", example[\"output_folder\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2242d4-2085-4f93-8ed6-27edb36919a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd97d1bb-3c7f-4f71-ab00-1eabc6f0281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = np.load(os.path.join(data_path, \"869_tokens.npy\")).squeeze(0).squeeze(0)\n",
    "audio_tokens = np.where(tokens < 0)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea5f12-2167-4ee5-9b8c-78e0c0103163",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.shape, audio_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac37d1-63d6-4939-802b-113bd5a8f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shapley_values = np.load(os.path.join(data_path, \"869_shapley_values.npy\")).squeeze(0).squeeze(0)\n",
    "audio_shapley_values = all_shapley_values[audio_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c256db-518b-4ef8-9894-9f959083389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_shapley_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2923b4ff-ea8d-4675-8d3b-9566a356ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_audio_shapley = np.abs(audio_shapley_values).sum(axis=1)\n",
    "pos_audio_shapley = np.clip(audio_shapley_values, a_min=0, a_max=None).sum(axis=1)\n",
    "neg_audio_shapley = np.clip(audio_shapley_values, a_min=None, a_max=0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9421098-2f0f-4d35-91bb-b70def447276",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_audio_shapley.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742def95-6267-4a7e-a9a1-8a5fb2bd0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "\n",
    "def plot_shapley_analysis(signal, audio_shapley_values, sample_rate,\n",
    "                         gt_start, gt_end, colormap='viridis', \n",
    "                         figsize=(12, 8), idx=None, output_token=None):\n",
    "    \"\"\"\n",
    "    Plot signal with Shapley value heatmaps in separate subplots with shared x-axis.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal : array-like\n",
    "        The input signal (waveform) to display\n",
    "    audio_shapley_values : array-like (2D)\n",
    "        Raw Shapley values (will be summed across features)\n",
    "    sample_rate : int\n",
    "        Sampling rate of the audio signal (Hz)\n",
    "    gt_start : float\n",
    "        Start time of ground truth event (seconds)\n",
    "    gt_end : float\n",
    "        End time of ground truth event (seconds)\n",
    "    colormap : str, optional\n",
    "        Matplotlib colormap to use (default: 'viridis')\n",
    "    figsize : tuple, optional\n",
    "        Figure size (width, height) in inches (default: (12, 8))\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate Shapley value components\n",
    "    abs_shapley = np.abs(audio_shapley_values)#.mean(axis=1)\n",
    "    pos_shapley = np.clip(audio_shapley_values, a_min=0, a_max=None)#.mean(axis=1)\n",
    "    neg_shapley = np.clip(audio_shapley_values, a_min=None, a_max=0)#.mean(axis=1)\n",
    "\n",
    "    if idx is None and output_token is None:\n",
    "        abs_shapley = abs_shapley.sum(axis=1)\n",
    "        pos_shapley = pos_shapley.sum(axis=1)\n",
    "        neg_shapley = neg_shapley.sum(axis=1)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(4, 1, figsize=figsize, \n",
    "                           sharex=True, \n",
    "                           gridspec_kw={'height_ratios': [2, 1, 1, 1]})\n",
    "    \n",
    "    total_duration = len(signal) / sample_rate\n",
    "    time_axis = np.linspace(0, total_duration, len(signal))\n",
    "    shapley_time_axis = np.linspace(0, total_duration, len(abs_shapley))\n",
    "    \n",
    "    # --- 1. Signal plot (top subplot) ---\n",
    "    ax_signal = axes[0]\n",
    "    ax_signal.plot(time_axis, signal, color='gray', alpha=0.7, linewidth=0.5)\n",
    "    ax_signal.set_ylabel('Amplitude', fontsize=10)\n",
    "    \n",
    "    # Add ground truth rectangle (only on signal plot)\n",
    "    ymin, ymax = ax_signal.get_ylim()\n",
    "    ax_signal.axvspan(gt_start, gt_end, ymin=0, ymax=1, \n",
    "                     color='red', alpha=0.3, label='Ground Truth')\n",
    "    ax_signal.legend(loc='upper right')\n",
    "    \n",
    "    # --- 2. Absolute Shapley values ---\n",
    "    ax_abs = axes[1]\n",
    "    im_abs = ax_abs.imshow(\n",
    "        np.repeat(abs_shapley.reshape(1, -1), 10, axis=0),\n",
    "        aspect='auto',\n",
    "        cmap=colormap,\n",
    "        extent=[0, total_duration, 0, 1],\n",
    "        vmin=0,  # Ensure consistent scaling\n",
    "        vmax=np.max(abs_shapley)\n",
    "    )\n",
    "    ax_abs.set_ylabel('Absolute\\nValue', rotation=0, ha='right', va='center', fontsize=10)\n",
    "    ax_abs.set_yticks([])\n",
    "    \n",
    "    # --- 3. Positive Shapley values ---\n",
    "    ax_pos = axes[2]\n",
    "    im_pos = ax_pos.imshow(\n",
    "        np.repeat(pos_shapley.reshape(1, -1), 10, axis=0),\n",
    "        aspect='auto',\n",
    "        cmap=colormap,\n",
    "        extent=[0, total_duration, 0, 1],\n",
    "        vmin=0,\n",
    "        vmax=np.max(abs_shapley)  # Same scale as absolute\n",
    "    )\n",
    "    ax_pos.set_ylabel('Positive\\nOnly', rotation=0, ha='right', va='center', fontsize=10)\n",
    "    ax_pos.set_yticks([])\n",
    "    \n",
    "    # --- 4. Negative Shapley values ---\n",
    "    ax_neg = axes[3]\n",
    "    im_neg = ax_neg.imshow(\n",
    "        np.repeat(np.abs(neg_shapley).reshape(1, -1), 10, axis=0),  # Show magnitude\n",
    "        aspect='auto',\n",
    "        cmap=colormap,\n",
    "        extent=[0, total_duration, 0, 1],\n",
    "        vmin=0,\n",
    "        vmax=np.max(abs_shapley)  # Same scale as absolute\n",
    "    )\n",
    "    ax_neg.set_ylabel('Negative\\nOnly', rotation=0, ha='right', va='center', fontsize=10)\n",
    "    ax_neg.set_yticks([])\n",
    "    ax_neg.set_xlabel('Time (seconds)', fontsize=12)\n",
    "    \n",
    "    # --- Colorbar ---\n",
    "    cax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    fig.colorbar(im_abs, cax=cax, label='Shapley Value Magnitude')\n",
    "    \n",
    "    # --- Formatting ---\n",
    "    fig_title = \"Shapley Values (sum over all output tokens)\"\n",
    "    if idx is not None:\n",
    "        fig_title = f'Shapley Values -- Output Token: {output_token}'\n",
    "    plt.suptitle(fig_title, y=0.98, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Remove boxes around subplots\n",
    "    for ax in axes:\n",
    "        ax.set_frame_on(False)\n",
    "    \n",
    "    plt.subplots_adjust(right=0.9, hspace=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae6a925-f524-42c5-96aa-871c822c61b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_shapley_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e419602f-6686-439c-82e5-0d8f4a9cd460",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, t in enumerate([\"The\", \"tele\", \"phone\", \"sound\", \"effect\", \"is\", \"present\", \"at\", \"the\", \"beginning\", \"of\", \"this\", \"music\", \"piece\", \".\"]):\n",
    "    plot_shapley_analysis(\n",
    "        x, \n",
    "        sample_rate=fs, \n",
    "        audio_shapley_values=audio_shapley_values[:,idx], \n",
    "        gt_start=0.5, \n",
    "        gt_end=3.5, \n",
    "        colormap=\"viridis\", \n",
    "        idx=idx,\n",
    "        output_token=t\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a5dddd-8033-468d-8ef6-b5fec978020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shapley_analysis(\n",
    "    x, \n",
    "    sample_rate=fs, \n",
    "    audio_shapley_values=audio_shapley_values, \n",
    "    gt_start=0.5, \n",
    "    gt_end=3.5, \n",
    "    colormap=\"viridis\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28fd62b-f8cf-4d29-8aad-1cbe5fdd8718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and tokenizer to encode output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef208d54-5e3b-4231-8c7b-28843e98d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "example[\"model_output\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db648f-0ab6-4f24-8ac8-8c7547c6ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "example[\"prompt\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7856e437-0419-496d-9e67-276c6554edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import rgb2hex\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "def highlight_tokens(shapley_values, tokens, max_abs_value=None):\n",
    "    \"\"\"\n",
    "    Highlight text tokens based on Shapley values using HTML span tags.\n",
    "    \n",
    "    Args:\n",
    "        shapley_values: List of Shapley values (one per token)\n",
    "        tokens: List of text tokens (same length as shapley_values)\n",
    "        max_abs_value: Optional maximum absolute value for color scaling.\n",
    "                      If None, will use max absolute value from shapley_values.\n",
    "    \n",
    "    Returns:\n",
    "        HTML string with tokens colored based on Shapley values\n",
    "    \"\"\"\n",
    "    if len(shapley_values) != len(tokens):\n",
    "        raise ValueError(\"Shapley values and tokens must have the same length\")\n",
    "    \n",
    "    shapley_values = np.array(shapley_values, dtype=float)\n",
    "    \n",
    "    # Determine color scaling\n",
    "    if max_abs_value is None:\n",
    "        max_abs_value = np.max(np.abs(shapley_values))\n",
    "    \n",
    "    # Normalize values to [-1, 1] range for coloring\n",
    "    normalized_values = shapley_values / (max_abs_value + 1e-10)\n",
    "    \n",
    "    # Create red (positive) and blue (negative) color maps\n",
    "    red_cmap = cm.Reds\n",
    "    blue_cmap = cm.Blues_r\n",
    "    \n",
    "    highlighted_text = []\n",
    "    for value, token in zip(normalized_values, tokens):\n",
    "        if value > 0:  # Positive impact\n",
    "            # Scale to [0.4, 1] range to avoid very light colors\n",
    "            intensity = 0.4 + 0.6 * abs(value)\n",
    "            rgba = red_cmap(intensity)\n",
    "        elif value < 0:  # Negative impact\n",
    "            intensity = 0.4 + 0.6 * abs(value)\n",
    "            rgba = blue_cmap(intensity)\n",
    "        else:  # Zero impact\n",
    "            highlighted_text.append(token)\n",
    "            continue\n",
    "            \n",
    "        hex_color = rgb2hex(rgba)\n",
    "        span = f'<span style=\"background-color: {hex_color}\">{token}</span>'\n",
    "        highlighted_text.append(span)\n",
    "    \n",
    "    return ' '.join(highlighted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75adc40-865f-4be1-b6a4-d9e788a96281",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = [0.5, -0.3, 0.1, -0.8, 0.0]\n",
    "tokens = [\"The\", \"movie\", \"was\", \"terrible\", \"!\"]\n",
    "\n",
    "html_output = highlight_tokens(shap_values, tokens)\n",
    "\n",
    "# To display in Jupyter notebook:\n",
    "from IPython.display import HTML\n",
    "HTML(html_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
