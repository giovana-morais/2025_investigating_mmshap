{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a127e719-8260-4e61-80f4-f8752d917114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702f980-6f46-4310-93aa-527f8fe34a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2e763-ba26-48fe-a255-4273ae0b4753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_output(json_list):\n",
    "    \"\"\"\n",
    "    receive a list of output files. load then and combine them into a single one.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for jf in json_list:\n",
    "        with open(jf, \"r\") as f:\n",
    "            data += json.load(f)\n",
    "    return data        \n",
    "\n",
    "def extract_answer_pandas(\n",
    "    model_output, \n",
    "    answer_options, \n",
    "    prefix=\"The correct answer is:\", \n",
    "    letter_options=[\"A\", \"B\", \"C\", \"D\"]):\n",
    "    \"\"\" adaptation of muchomusic function but applies to our pandas dataframe \"\"\"\n",
    "\n",
    "    output = model_output.split(prefix)[-1].strip()\n",
    "    response = list(set(letter_options).intersection(output))\n",
    "    if len(response) == 1:\n",
    "        final_response = letter_options.index(response[0])\n",
    "    else:\n",
    "        normalized_output = output.lower().strip()\n",
    "        normalized_answers = [j.lower().strip() for j in answer_options]\n",
    "\n",
    "        for j, answer in enumerate(normalized_answers):\n",
    "            if answer in normalized_output:\n",
    "                final_response = j\n",
    "                break\n",
    "            else:\n",
    "                final_response = -1\n",
    "    return final_response\n",
    "\n",
    "def compare_answers(response, answer_orders):\n",
    "    \"\"\"\n",
    "    return correct/incorrect/unanswered\n",
    "    \"\"\"\n",
    "    answer = 0\n",
    "    if response == answer_orders.index(0):\n",
    "        answer = 1\n",
    "    elif response == -1:\n",
    "        answer = -1\n",
    "\n",
    "    return answer\n",
    "\n",
    "def accuracy(df):\n",
    "    return df[df[\"final_answer\"] == 1][\"final_answer\"].count()/df[\"final_answer\"].count()\n",
    "\n",
    "\n",
    "def json_to_df(model, experiment, model_output, musiccaps_only, mmshap=True):\n",
    "    df = pd.DataFrame(model_output)\n",
    "    df[\"model\"] = model\n",
    "    df[\"experiment\"] = experiment\n",
    "    df[\"extracted_response\"] = df[[\"model_output\", \"answers\"]].apply(lambda x: extract_answer_pandas(x.model_output, x.answers), axis=1)\n",
    "    df[\"final_answer\"] = df[[\"extracted_response\", \"answer_orders\"]].apply(lambda x: compare_answers(x.extracted_response, x.answer_orders), axis=1)\n",
    "    if mmshap:\n",
    "        df[\"mmshap_audio\"] = 1-df[\"mmshap_text\"]\n",
    "\n",
    "    if musiccaps_only:\n",
    "        df = df[df[\"dataset\"] == \"musiccaps\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad888acd-6b60-418b-8048-c28a276dbf1c",
   "metadata": {},
   "source": [
    "### load QwenAudio results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ff8148-5a9b-4446-83e7-531d679b1467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original few shot default\n",
    "qwen_fs_list = glob.glob(\"experiments/output_data/parallel_mmshap_qwenaudio_original_few_shot_20_*\")\n",
    "qwen_fs = combine_output(qwen_fs_list)\n",
    "\n",
    "len(qwen_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c525b-adf5-4fc9-b624-20525fe934c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# description\n",
    "qwen_desc_list = glob.glob(\"experiments/output_data/parallel_mmshap_qwenaudio_description_5_*\")\n",
    "qwen_desc = combine_output(qwen_desc_list)\n",
    "len(qwen_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda0a19f-7ac6-49e0-93b0-cda36d9f1cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question only\n",
    "qwen_qo_list = glob.glob(\"experiments/output_data/parallel_mmshap_qwenaudio_question_only_5_*\")\n",
    "qwen_qo = combine_output(qwen_qo_list)\n",
    "len(qwen_qo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128a0cb5-6b27-4560-a6b6-988390be6d05",
   "metadata": {},
   "source": [
    "### load MU-LLaMA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e13150f-0391-403c-8c6a-d542d5a38193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original few shot default\n",
    "#mullama_fs_list = glob.glob(\"experiments/output_data/mullama_original_few_shot_1_*\") + glob.glob(\"experiments/output_data/musiccaps/mullama_original_few_shot_1_*\")\n",
    "mullama_fs_list = glob.glob(\"experiments/output_data/mullama_original_few_shot_1_*\")\n",
    "print(len(mullama_fs_list))\n",
    "mullama_fs = combine_output(mullama_fs_list)\n",
    "\n",
    "len(mullama_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fe9181-99b9-47dd-a75f-a8bbf1c900cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# description (not complete yet)\n",
    "# mullama_desc_list = glob.glob(\"experiments/output_data/mullama_description_4_*\")\n",
    "mullama_desc_list = glob.glob(\"experiments/output_data/mullama_description_5_*\")\n",
    "print(len(mullama_desc_list)*5)\n",
    "mullama_desc = combine_output(mullama_desc_list)\n",
    "len(mullama_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab68cd9-d284-4b53-a524-6c91229f1f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# description (not complete yet)\n",
    "mullama_qo_list = glob.glob(\"experiments/output_data/mullama_question_only_5_*\")\n",
    "print(len(mullama_qo_list)*5)\n",
    "mullama_qo = combine_output(mullama_qo_list)\n",
    "len(mullama_qo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26abe82c-eb2f-485f-9eb2-8d8756b25f14",
   "metadata": {},
   "source": [
    "## load LLaMA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352e11a-23a4-411f-b878-8a8097b3531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# description (not complete yet)\n",
    "llama = glob.glob(\"experiments/output_data/llama_original.json\")\n",
    "llama = combine_output(llama)\n",
    "len(llama)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c840fd2b-8fab-4a1d-9b99-41796b77bead",
   "metadata": {},
   "source": [
    "# inspect T-SHAP for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff81a32-03aa-4980-b8b6-6f401c253458",
   "metadata": {},
   "outputs": [],
   "source": [
    "musiccaps_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4de8c-8593-49cd-aca4-d4f4ead690ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama = json_to_df(model=\"LLaMA2\", experiment=\"few_shot\", model_output=llama, musiccaps_only=musiccaps_only, mmshap=False)\n",
    "print(f\"Accuracy for LLaMA few shot: {accuracy(llama)} ({len(llama)} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bbd925-3e10-496d-9590-47e634b023cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_fs_df = json_to_df(model=\"QwenAudio\", experiment=\"few_shot\", model_output=qwen_fs, musiccaps_only=musiccaps_only).dropna()\n",
    "qwen_desc_df = json_to_df(model=\"QwenAudio\", experiment=\"description\", model_output=qwen_desc, musiccaps_only=musiccaps_only).dropna()\n",
    "qwen_qo_df = json_to_df(model=\"QwenAudio\", experiment=\"question_only\", model_output=qwen_qo, musiccaps_only=musiccaps_only).dropna()\n",
    "\n",
    "qwen_fs_df.to_csv(\"qwenaudio_fewshot_results.csv\", index=False)\n",
    "qwen_desc_df.to_csv(\"qwenaudio_desc_results.csv\", index=False)\n",
    "qwen_qo_df.to_csv(\"qwenaudio_qo_results.csv\", index=False)\n",
    "\n",
    "print(f\"Accuracy for QwenAudio few shot: {accuracy(qwen_fs_df)} ({len(qwen_fs_df)} samples)\")\n",
    "print(f\"Accuracy for QwenAudio question only: {accuracy(qwen_qo_df)} ({len(qwen_qo_df)} samples)\")\n",
    "print(f\"Accuracy for QwenAudio description: {accuracy(qwen_desc_df)} ({len(qwen_desc_df)} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e33cc79-8680-476f-82ce-fc9efaf67615",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_fs_df = json_to_df(model=\"MU-LLaMA\", experiment=\"few_shot\", model_output=mullama_fs, musiccaps_only=musiccaps_only)\n",
    "mu_fs_df = mu_fs_df.dropna()\n",
    "mu_desc_df = json_to_df(model=\"MU-LLaMA\", experiment=\"description\", model_output=mullama_desc, musiccaps_only=musiccaps_only)\n",
    "mu_desc_df = mu_desc_df.dropna()\n",
    "mu_qo_df = json_to_df(model=\"MU-LLaMA\", experiment=\"question_only\", model_output=mullama_qo, musiccaps_only=musiccaps_only)\n",
    "mu_qo_df = mu_qo_df.dropna()\n",
    "\n",
    "mu_fs_df.to_csv(\"mullama_fewshot_results.csv\", index=False)\n",
    "mu_desc_df.to_csv(\"mullama_desc_results.csv\", index=False)\n",
    "mu_qo_df.to_csv(\"mullama_qo_results.csv\", index=False)\n",
    "\n",
    "print(f\"Accuracy for MU-LLaMA few shot: {accuracy(mu_fs_df)} ({len(mu_fs_df)} samples)\")\n",
    "print(f\"Accuracy for MU-LLaMA question only: {accuracy(mu_qo_df)} ({len(mu_qo_df)} samples)\")\n",
    "print(f\"Accuracy for MU-LLaMA description: {accuracy(mu_desc_df)} ({len(mu_desc_df)} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e49af-4b49-438b-8898-06042cffb268",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([\n",
    "    qwen_fs_df, qwen_desc_df, qwen_qo_df,\n",
    "    mu_fs_df, mu_desc_df, mu_qo_df\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f85fb68-9716-4d9d-b591-7dcc0e15dd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get genres and categories information\n",
    "all_genres = qwen_fs_df[\"genre\"].unique()\n",
    "\n",
    "knowledge_categories = []\n",
    "for i in qwen_fs_df[\"knowledge\"].tolist():\n",
    "    knowledge_categories += i\n",
    "\n",
    "knowledge_categories = list(set(knowledge_categories))\n",
    "\n",
    "reasoning_categories = []\n",
    "for i in qwen_fs_df[\"reasoning\"].tolist():\n",
    "    reasoning_categories += i\n",
    "\n",
    "reasoning_categories = list(set(reasoning_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe8483-5b6b-42a2-a462-ea06b62de7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby([\"experiment\", \"model\"]).agg({\n",
    "    # \"mmshap_text\": [\"mean\", \"median\", \"std\"], \n",
    "    \"mmshap_audio\": [\"mean\", \"median\", \"min\", \"max\", \"count\"]\n",
    "    # \"final_answer\": \"count\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bbc224-c310-47aa-be09-f22fcf4d19b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby([\"experiment\", \"model\", \"final_answer\"]).agg({\n",
    "    # \"mmshap_text\": [\"mean\", \"std\"], \n",
    "    \"mmshap_audio\": [\"mean\", \"std\"],#, \"median\", \"min\", \"max\"]\n",
    "    \"final_answer\": \"count\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bce3a05-689a-4de1-a210-a3fde266e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results[\"dataset\"] == \"musiccaps\"].groupby([\"experiment\", \"model\", \"dataset\"]).agg({\n",
    "    # \"mmshap_text\": [\"mean\", \"median\", \"std\"], \n",
    "    \"mmshap_audio\": [\"mean\", \"std\", \"count\"], #, \"median\"], # \"min\", \"max\"]\n",
    "})\n",
    "# .plot(kind=\"bar\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208792fb-734b-4b84-bade-d9f328dd5cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby([\"experiment\", \"model\"]).agg({\n",
    "    # \"mmshap_text\": [\"mean\", \"median\", \"std\"], \n",
    "    \"mmshap_audio\": [\"mean\", \"median\", \"min\", \"max\"],\n",
    "    \"final_answer\": \"count\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a033a317-0993-4986-9a69-4da4bb84ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = results.groupby([\"experiment\", \"model\", \"final_answer\"]).agg({\n",
    "    \"mmshap_audio\": [\"mean\", \"median\", \"max\", \"min\"], \n",
    "    # \"final_answer\": \"count\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd964e84-5903-4a73-8cfc-3f67281a56d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5101020-3d68-4413-955a-128a3f9672fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby([\"experiment\", \"model\"])[[\"mmshap_audio\"]].boxplot(subplots=False)\n",
    "plt.xlabel(\"Experiment\")\n",
    "plt.ylabel(\"A-SHAP\")\n",
    "# locs, labels = plt.xticks()\n",
    "# new_labels = [i.get_text().split(\",\")[0][1:] for i in labels]\n",
    "# plt.xticks(ticks=locs, labels=new_labels, rotation=45)\n",
    "# print(locs, labels)\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0e8a5d-63d6-489b-bc6c-748ea1d3c868",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3f6728-dcea-46e2-bb7e-19e5aab83f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_exploded = results[results[\"experiment\"].isin([\"few_shot\", \"question_only\"])].explode(\"knowledge\").explode(\"reasoning\")\n",
    "\n",
    "results_knowledge = results_exploded.dropna(subset=[\"knowledge\"])\n",
    "results_reasoning = results_exploded.dropna(subset=[\"reasoning\"])\n",
    "\n",
    "results_exploded\n",
    "\n",
    "knowledge_grouped = results_knowledge.groupby([\"knowledge\", \"model\", \"experiment\"]).agg({\"mmshap_audio\": \"mean\"}).reset_index().rename(columns={\"knowledge\": \"question_type\"})\n",
    "\n",
    "reasoning_grouped = results_reasoning.groupby([\"reasoning\", \"model\", \"experiment\"]).agg({\"mmshap_audio\": \"mean\"}).reset_index().rename(columns={\"reasoning\": \"question_type\"})\n",
    "\n",
    "finegrained_results = pd.concat([knowledge_grouped, reasoning_grouped])\n",
    "\n",
    "finegrained_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe7e69-a5c0-458a-9aa9-579cfb4a7b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results = results[[\"mmshap_audio\", \"model\", \"experiment\"]].groupby([\"model\", \"experiment\"]).mean().reset_index()\n",
    "\n",
    "questions_label_mapping ={\n",
    "    \"temporal relations between elements\": \"Temporal \\n Relations\",\n",
    "    \"mood and expression\": \"Mood\",\n",
    "    \"lyrics\": \"Lyrics\",\n",
    "    \"historical and cultural context\": \"Cultural \\n Context\",\n",
    "    \"genre and style\": \"Genre\",\n",
    "    \"functional context\": \"Functional \\n Context\",\n",
    "    \"melody\": \"Melody\",\n",
    "    \"harmony\": \"Harmony\",\n",
    "    \"metre and rhythm\": \"Metre & \\nRhythm\",\n",
    "    \"structure\": \"Structure\",\n",
    "    \"performance\": \"Performance\",\n",
    "    \"instrumentation\": \"Instrumentation\",\n",
    "    \"sound texture\": \"Sound \\n Texture\",\n",
    "    \"dynamics and expression\": \"Dynamics & \\nExpression\",\n",
    "}\n",
    "\n",
    "# temporary just so i can plot stuff\n",
    "finegrained_results = finegrained_results.fillna(0)\n",
    "agg_results = agg_results.fillna(0)\n",
    "\n",
    "finegrained_with_ref = pd.merge(\n",
    "    left=finegrained_results, \n",
    "    right=agg_results,\n",
    "    how='left',\n",
    "    left_on=['model', 'experiment'],\n",
    "    right_on=['model', 'experiment'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6fe41a-a848-4d34-8c1b-812407eb1796",
   "metadata": {},
   "outputs": [],
   "source": [
    "finegrained_with_ref = finegrained_with_ref.rename(columns={\"mmshap_audio_x\": \"question_type_ashap\", \"mmshap_audio_y\": \"dataset_ashap\"})\n",
    "\n",
    "finegrained_with_ref[\"question_cat\"] = finegrained_with_ref.apply(lambda x: questions_label_mapping[x[\"question_type\"]], axis=1)\n",
    "finegrained_with_ref[\"diff\"] = finegrained_with_ref[\"question_type_ashap\"] - finegrained_with_ref[\"dataset_ashap\"]\n",
    "\n",
    "finegrained_with_ref[\"experiment_name\"] = finegrained_with_ref[\"experiment\"].apply(lambda x: \"M-Choice\" if x == \"few_shot\" else \"Q-Only\")\n",
    "\n",
    "tmp = finegrained_with_ref[[\"model\", \"experiment_name\", \"question_cat\", \"diff\"]]\n",
    "\n",
    "qwen_tmp = tmp[tmp[\"model\"] == \"QwenAudio\"]\n",
    "mu_tmp = tmp[tmp[\"model\"] == \"MU-LLaMA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df058a7-fe12-4919-a9de-5a6e39893321",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, sharex=True, sharey=False)\n",
    "for a in ax:\n",
    "    a.spines['top'].set_visible(False)\n",
    "    a.spines['right'].set_visible(False)\n",
    "    a.spines['left'].set_visible(False)\n",
    "    \n",
    "    a.axhline(y=0, color=\"black\", linewidth=0.5, alpha=0.5)\n",
    "    a.grid(axis=\"y\")\n",
    "    a.set(axisbelow=True)\n",
    "\n",
    "sns.barplot(qwen_tmp, x=\"question_cat\", y=\"diff\", hue=\"experiment_name\", ax=ax[0])\n",
    "sns.barplot(mu_tmp, x=\"question_cat\", y=\"diff\", hue=\"experiment_name\", ax=ax[1])\n",
    "plt.xticks(ticks=qwen_tmp[\"question_cat\"].values, rotation=73, fontsize=10)\n",
    "\n",
    "ax[0].legend(loc=\"upper center\", ncols=2, bbox_to_anchor=(0.5,1.25))\n",
    "ax[1].get_legend().remove()\n",
    "\n",
    "ax[0].set_ylim(-0.1, 0.1)\n",
    "ax[1].set_ylim(-0.01, 0.01)\n",
    "\n",
    "ax[1].set_xlabel(\"\")\n",
    "ax[0].set_ylabel(\"QwenAudio\\n$\\Delta$ A-SHAP$_{avg}$\")\n",
    "ax[1].set_ylabel(\"MU-LLaMA\\n$\\Delta$ A-SHAP$_{avg}$\")\n",
    "plt.savefig(\"paper_figures/ashap_avg_comparison.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae0235-8906-40d2-8cc0-f85181bf2e53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# spider plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d96ed7-9ca3-4c7a-bb48-6e2bfb8ef1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_exploded = results[results[\"experiment\"].isin([\"few_shot\", \"question_only\"])].explode(\"knowledge\").explode(\"reasoning\")\n",
    "\n",
    "results_knowledge = results_exploded.dropna(subset=[\"knowledge\"])\n",
    "results_reasoning = results_exploded.dropna(subset=[\"reasoning\"])\n",
    "\n",
    "knowledge_grouped = results_knowledge.groupby([\"knowledge\", \"model\", \"experiment\"]).agg({\"mmshap_audio\": \"mean\"}).reset_index().rename(columns={\"knowledge\": \"question_type\"})\n",
    "\n",
    "reasoning_grouped = results_reasoning.groupby([\"reasoning\", \"model\", \"experiment\"]).agg({\"mmshap_audio\": \"mean\"}).reset_index().rename(columns={\"reasoning\": \"question_type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7473cf05-2a30-4949-b49f-f451706e1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "finegrained_results = pd.concat([knowledge_grouped, reasoning_grouped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147e9a3-d4b7-46e8-8709-96ba9d406bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_label_mapping ={\n",
    "    \"temporal relations between elements\": \"Temporal \\n Relations\",\n",
    "    \"mood and expression\": \"Mood\",\n",
    "    \"lyrics\": \"Lyrics\",\n",
    "    \"historical and cultural context\": \"Cultural \\n Context\",\n",
    "    \"genre and style\": \"Genre\",\n",
    "    \"functional context\": \"Functional \\n Context\",\n",
    "    \"melody\": \"Melody\",\n",
    "    \"harmony\": \"Harmony\",\n",
    "    \"metre and rhythm\": \"Metre & \\nRhythm\",\n",
    "    \"structure\": \"Structure\",\n",
    "    \"performance\": \"Performance\",\n",
    "    \"instrumentation\": \"Instrumentation\",\n",
    "    \"sound texture\": \"Sound \\n Texture\",\n",
    "    \"dynamics and expression\": \"Dynamics & \\nExpression\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb605c4a-4a56-43c7-ac41-d5aeec9643f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_map = {\"question_only\": \"Question Only\", \"few_shot\": \"Few-Shot\"}\n",
    "style_map = {\n",
    "    \"QwenAudio\": {\n",
    "        \"question_only\": {\"color\": \"deepskyblue\", \"linestyle\":'--', \"label\": \"Qwen-Audio - Q-Only\"},\n",
    "        \"few_shot\": {\"color\": \"darkblue\", \"linestyle\": ':', \"label\": \"Qwen-Audio - M-Choice\"}\n",
    "    },\n",
    "    \"MU-LLaMA\": {\n",
    "        \"question_only\": {\"color\": \"orangered\", \"linestyle\":'-', \"label\": \"MU-LLaMA - Q-Only\"},\n",
    "        \"few_shot\": {\"color\": \"darkred\", \"linestyle\":'-.', \"label\": \"MU-LLaMA - M-Choice\"},\n",
    "    }\n",
    "    # [\"MU-LLaMA\"][\"few_shot\"]: {color=\"darkgreen\", linestyle='solid', label=\"Qwen-Audio -- Few Shot\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b13dbc-02ae-4a3a-9fc2-fb6d969687bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(finegrained_results[\n",
    "            (finegrained_results[\"experiment\"] == \"question_only\") &\n",
    "            (finegrained_results[\"model\"] == \"QwenAudio\")\n",
    "        ][\"question_type\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958247ea-baa2-4e80-9c40-a649a97388bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this, we are comparing few shot vs question only\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5), subplot_kw=dict(polar=True))\n",
    "\n",
    "# Get the categories (knowledge areas)\n",
    "categories = list(questions_label_mapping.values())\n",
    "N = len(categories)\n",
    "\n",
    "# What will be the angle of each axis in the plot\n",
    "angles = np.linspace(0, 2 * np.pi, N, endpoint=False).tolist()\n",
    "angles += angles[:1]\n",
    "experiments = finegrained_results[\"experiment\"].unique()\n",
    "\n",
    "# Plot each experiment\n",
    "for model in [\"QwenAudio\"]: #, \"MU-LLaMA\"]:\n",
    "    for experiment in experiments:\n",
    "        values = finegrained_results[\n",
    "            (finegrained_results[\"experiment\"] == experiment) &\n",
    "            (finegrained_results[\"model\"] == model)\n",
    "        ][\"mmshap_audio\"].values\n",
    "        #values += values[:1]\n",
    "        print(model, experiment, len(angles), len(values))\n",
    "        values = np.append(values, values[0])\n",
    "        print(values)\n",
    "        ax.plot(angles, values, **style_map[model][experiment])\n",
    "        ax.fill(angles, values, alpha=0.05)\n",
    "\n",
    "\n",
    "categories_raw = finegrained_results[\n",
    "            (finegrained_results[\"experiment\"] == experiment) &\n",
    "            (finegrained_results[\"model\"] == model)\n",
    "        ][\"question_type\"].unique()\n",
    "\n",
    "ax.tick_params(pad=22)\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels([questions_label_mapping[c] for c in categories_raw], fontsize=10)\n",
    "ax.set_yticks(np.linspace(0,1,6), np.round(np.linspace(0,1,6),2), color=\"black\", size=10, alpha=0.7)\n",
    "ax.set_ylim(0, 0.2)\n",
    "#ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, 1.3), ncol=2)\n",
    "ax.legend(loc=\"lower center\", bbox_to_anchor=(0.5, -0.3), ncol=2)\n",
    "\n",
    "\n",
    "# plt.savefig(\"paper_figures/spider_plot.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbbb0d6-40d0-4304-a25c-ab9aea6334e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
